{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download txt from https://github.com/ceclinux/huffman/blob/master/莎士比亚全集英文版.txt and save it into data folder, use curl\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "!curl -o data/shakespeare.txt https://raw.githubusercontent.com/ceclinux/huffman/master/%E8%8E%8E%E5%A3%AB%E6%AF%94%E4%BA%9A%E5%85%A8%E9%9B%86%E8%8B%B1%E6%96%87%E7%89%88.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file and read the first 1000 characters\n",
    "with open('data/shakespeare.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "    print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tokens = re.findall(r\"[a-zA-Z]+|[^\\s\\w]|[\\n]\", text)\n",
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a frequency table, from highest to lowest, and draw a bar chart\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "frequency = Counter(tokens)\n",
    "frequency = dict(sorted(frequency.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequency.values())\n",
    "plt.semilogy()\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "frequency = dict(list(frequency.items())[:vocab_size])\n",
    "transition_matrix = np.zeros((vocab_size, vocab_size), dtype=int)\n",
    "\n",
    "for i in tqdm.tqdm(range(1, len(tokens))):\n",
    "    left = tokens[i-1]\n",
    "    right = tokens[i]\n",
    "    if left in frequency and right in frequency:\n",
    "        transition_matrix[list(frequency.keys()).index(left)][list(frequency.keys()).index(right)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate according to the transition matrix\n",
    "def generate(first='the', length=100):\n",
    "    sentence = [first]\n",
    "    index = list(frequency.keys()).index(first)\n",
    "    for _ in range(length):\n",
    "        next_index = np.random.choice(vocab_size, p=transition_matrix[index]/transition_matrix[index].sum())\n",
    "        sentence.append(list(frequency.keys())[next_index])\n",
    "        index = next_index\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "print(generate('she'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNScratch(nn.Module):  #@save\n",
    "    \"\"\"The RNN model implemented from scratch.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, sigma=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim, self.hidden_dim = input_dim, hidden_dim\n",
    "        self.W_ih = nn.Parameter(\n",
    "            torch.randn(input_dim, hidden_dim) * sigma)\n",
    "        self.W_hh = nn.Parameter(\n",
    "            torch.randn(hidden_dim, hidden_dim) * sigma)\n",
    "        self.b_h = nn.Parameter(torch.zeros(hidden_dim)) # equivalenet to b_ih + b_hh in the slides notation.\n",
    "\n",
    "\n",
    "    def forward(self, inputs, state=None):\n",
    "        # inputs shape: (num_steps, batch_size, input_dim)\n",
    "        # state shape: (batch_size, hidden_dim)\n",
    "        if state is None:\n",
    "            # Initial state with shape: (batch_size, hidden_dim)\n",
    "            state = torch.zeros((inputs.shape[1], self.hidden_dim),\n",
    "                            device=inputs.device)\n",
    "        else:\n",
    "            state, = state\n",
    "        outputs = []\n",
    "        for X in inputs:  # Shape of inputs: (num_steps, batch_size, input_dim)\n",
    "            state = torch.tanh(torch.matmul(X, self.W_ih) +\n",
    "                            torch.matmul(state, self.W_hh) + self.b_h)\n",
    "            outputs.append(state)\n",
    "        return torch.stack(outputs), (state,)\n",
    "    \n",
    "rnn = RNNScratch(input_dim=16, hidden_dim=512)\n",
    "    \n",
    "\n",
    "# create a input sequence\n",
    "LEN = 100 # sequence length\n",
    "BATCH = 32 # batch size\n",
    "DIM = 16 # input dimension\n",
    "x = torch.randn(LEN, BATCH, DIM)\n",
    "y, state = rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output shape:\", y.shape) # sequence length * batch size * hidden dimension\n",
    "print(\"state shape:\", state[0].shape) # batch size * hidden dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4om",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
